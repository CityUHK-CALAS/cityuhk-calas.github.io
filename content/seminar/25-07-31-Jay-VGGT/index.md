---
title: "VGGT: Visual Geometry Grounded Transformer"

event: CALAS Regular Meetings

location: G4302
address:
  street: 83 Tat Chee Avenue
  city: Kowloon
  region: Hong Kong
  postcode: '999077'
  country: China

summary: |
  **Speaker**: Jay Jianyuan WANG, Joint PhD Student, Meta AI Research and Visual Geometry Group (VGG), University of Oxford<br>
  **Time**: July 31 2025 (Thur) at 18:00 HKT


# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: '2025-07-31T18:00:00Z'
date_end: '2025-07-31T19:00:00Z'
all_day: false

# Schedule page publish date (NOT talk date).
publishDate: '2025-07-23T00:00:00Z'

authors: []
tags: []

# Is this a featured talk? (true/false)
featured: false
reading_time: false
share: false
profile: false

url_code: ''
url_pdf: ''
url_slides: ''
url_video: ''

# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides:

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects:
---
## Speaker
Jay Jianyuan WANG, Joint PhD Student <br>
Meta AI Research and Visual Geometry Group (VGG), University of Oxford

## Time
July 31 2025 (Thur) at 18:00 HKT

## Abstract
<div style="text-align: justify">
We present VGGT, a feed-forward neural network that directly infers all key 3D attributes of a scene, including camera parameters, point maps, depth maps, and 3D point tracks, from one, a few, or hundreds of its views. This approach is a step forward in 3D computer vision, where models have typically been constrained to and specialized for single tasks. It is also simple and efficient, reconstructing images in under one second, and still outperforming alternatives without their post-processing utilizing visual geometry optimization techniques. The network achieves state-of-the-art results in multiple 3D tasks, including camera parameter estimation, multi-view depth estimation, dense point cloud reconstruction, and point tracking. We also show that using pretrained VGGT as a feature backbone significantly enhances downstream tasks, such as non-rigid point tracking and feed-forward novel view synthesis.
</div>

## Biography
<div style="text-align: justify">
Jianyuan Wang is a joint PhD student at Meta AI Research and the Visual Geometry Group (VGG), University of Oxford, currently in his third year. His research focuses on 3D understanding, particularly the reconstruction of 3D scenes from images, from PoseDiffusion, VGGSfM, to VGGT. His work has been recognized with several honors, including CVPR 2025 Best Paper Award.
</div>
